# unilab-mario

## リポジトリのクローン

以下のコマンドをクローンしたいディレクトリで実行してください。

```
git clone https://github.com/murata-lab/unilab-mario.git
```

## とりあえず動かしたい場合

### １．実行環境の準備

以下のコマンドを実行して必要なライブラリをインストールしてください。

```text
pip install sounddevice numpy matplotlib scipy tensorflow librosa
```

次に、インストールが正常に実行されたか確認します。以下のコマンドを実行してエラーが出ないことを確認してください。

```text
python -c "import sounddevice, numpy, matplotlib, scipy, tensorflow, librosa"
```

### ２．実行

実際の分離を行うには``src``ディレクトリにある``prediction.py``を使います。このとき、訓練済モデルを使う場合は...

## 自分で用意したデータセットを使う場合や新たにデータを追加して分離精度を上げたい場合

### １．データセットの準備

録音にはマイクが必要であるため、ローカルマシンでやってください。パッケージのインストールが必要になりますので、最後に記載された方法で不要なパッケージの削除や、バージョンの変更を行ってください。

データの取得には``recording``ディレクトリにある``rec.py``を使います。

ローカルマシンで実行するため、パッケージのバージョンが変わる可能性があります。以下のコマンドで自身の環境にインストールされているパッケージのバージョンとリストを取得しておいてください。

```text
pip list
```

まずは実行環境の準備です。以下のコマンドを実行して必要なライブラリをインストールしてください。

```text
pip install sounddevice==0.4.6 numpy==1.22.3 matplotlib==3.5.1
```

次に、インストールが正常に実行されたか確認します。以下のコマンドを実行してエラーが出ないことを確認してください。

```text
python -c "import sounddevice, numpy, matplotlib"
```

実行環境の準備はこれで完了です。次に``rec.py``の設定を行います。以下の項目を設定してください。

- 44行目 ``file_path`` : 取得したデータの保存先のパスを指定してください。

- 68行目 ``val > 0.xx`` : 録音を開始する音量を指定します。デフォルトでは0.xx=0.05です。

- 90行目 ``recording_time`` : 録音時間です。デフォルトでは0.50秒になってます。

- 91行目 ``downsample`` : サンプリングレートをこの値で割った値にします。デフォルトは1です。

次にデータの取得方法についてです。データは１人が「とまれ」「すすめ」「もどれ」「ジャンプ」の4単語を順番に言うことを想定しています。データのサンプルをとる人の番号を26行目の``recording_number``に設定します。ここまで設定ができたら``rec.py``を実行してください。

実行するとマイクで拾った音声をリアルタイムで表示するグラフが現れます。コードの68行目で指定した値を音量が上回ると録音が開始され、4回録音すると自動で終了します。次の人の録音をする場合は``recording_number``の値を変更して再度実行してください。

録音データは全てcsvファイルで保存されます。直前に録音された波形は``hoge#.png``で見ることができます。正常に録音されたかの確認に使用してください。

以下は不要なパッケージやバージョンの変更方法です。上が削除方法、下がバージョンの変更方法です。

```text
pip uninstall パッケージ名
pip install パッケージ名==バージョン
```

### ２．トレーニングの設定

モデルの構築とトレーニングには``training``ディレクトリにある``train.py``を使います。まずは以下の項目の設定をします。

- 11行目 ``num_files`` : データセットのcsvファイルの数です。

- 14行目 ``div`` : データをトレーニング用とテスト用に分割するインデックスを指定します。

- 17行目 ``mode`` : 特徴量抽出機を選択します。stft = 0, mfcc = 1です。

- 20行目 ``directory`` : 学習に使うデータセットのディレクトリを選択します。

以上で``train.py``の設定は完了です。

### ３．モデルの構築とトレーニング

第２項で設定した``tarin.py``の実行に必要な環境は同ディレクトリにある``Dockerfile``で用意します。

まずは以下のコマンドを実行し、ビルドを行ってください。

```text
make build
```

次に以下のコマンドを実行すると、コンテナ内の8888ポートがホストマシンの8888ポートにマッピングされます。Dockerコンテナを起動すると、Jupyter Labが自動的に開始され、コンテナのIPアドレスとポート番号（デフォルトは8888）にアクセスすることでJupyter Labに接続できます。

```text
make run
```

完了したら、各自のWebブラウザで以下のURLに接続することでコンテナ内部で作業ができるようになります。

```text
http://localhost:8888
```

ここからはコンテナ内の作業になるので、ファイルの内容の変更や訓練されたモデルなどは保存されない点に注意してください。保存したい場合は必要に応じてダウンロードしてください。

Jupyter Labで``train.py``を実行するには``run.ipynb``を開いてすでに書かれている以下のコマンドを実行してください。

```JupyterNotebook
%run train.py
```

実行が完了すると同じディレクトリに指定した名前のモデル（h5ファイル）が生成されます。これをダウンロードして``src``ディレクトリに入れてください。ここまで完了したらJupyter Labは閉じてしまって構いません。

終了するときは必ず以下のコマンドを実行してください。

```text
make stop
```

以降、作成したモデルを動かすのは``とりあえず動かしたい場合``と同様です。お疲れさまでした。
